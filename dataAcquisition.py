import logging
import requests
import os
from bs4 import BeautifulSoup
from urllib import urljoin

class ParqueDownloader:
    def __init__(self, url):
        self.url = url
        self.logger = self._setup_logger()

    def _setup_logger(self):
        logging.basicConfig(filename='dataAquisition_log.txt', level=logging.INFO,
                            format='%(asctime)s - %(levelname)s - %(message)s')
        return logging.getLogger(__name__)
    
    def get_parque_links(self):
        # get the URL and store that in response variable
        response = requests.get(self.url)

        if response.status_code == 200:
            soup = BeautifulSoup(response.content, 'html.parser')

            # Using list comprehension to extract the value of href for each <a> tags found. 
            # Find links that contain "Yellow Taxi Trip Records" and end with ".parquet"
            parquet_links = [a['href'] for a in soup.find_all('a', href=True) if 'Yellow Taxi Trip Records' in a.text and a['href'].endswith('.parquet')]
            return parquet_links
        else:
            self.logger.error(f"Failed to retrieve content from the URL. Status code: {response.status_code}")
            return []

    def download_parquet_files(self, links, dest_path):
        """
        Download Parquet files from the specified links to the destination path.

        Args:
        - links (list): List of relative URLs for Parquet files.
        - dest_path (str): Destination path where files should be downloaded.

        Returns:
        None
        Explanation:
        - For each link in the provided list, the method constructs a full URL by joining the base URL (self.url) with the link.
          This ensures that the full URL is complete and points to the exact location of the Parquet file on the server.

        - The file_name is then generated by joining the destination path (dest_path) with the base name of the full URL.
          This ensures that the downloaded file is saved with the same name as it has on the server.

        - If the file already exists in the destination path, the method skips the download for that specific file.

        - The method logs information about the download process, including success, failure, or skipping due to existing files.
        """
        for link in links:
            full_url = urljoin(self.url, link)
            file_name = os.path.join(dest_path, os.path.basename(full_url))

            # Check if the file already exists in the destination path
            if os.path.exists(file_name):
                self.logger.info(f"Skipping download. File already exists: {file_name}")
                continue

            # Download the file if it doesn't exist
            try:
                response = requests.get(full_url)
                if response.status_code == 200:
                    with open(file_name, 'wb') as file:
                        file.write(response.content)
                    self.logger.info(f"Downloaded: {file_name}")
                else:
                    self.logger.warning(f"Failed to download {file_name}. Status code: {response.status_code}")
            except Exception as e:
                self.logger.error(f"Error downloading {file_name}: {e}")


    






